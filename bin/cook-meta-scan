#!/usr/bin/python3

import argparse
import os,codecs
import math,time
import json

def extract_cooked_meta( raw_meta ):
    cooked_meta = raw_meta[4:-2]
    return cooked_meta.strip()

def extract_raw_meta( fn ):
    raw_meta=[]
    # @FIXME handle file open failure exception gracefully
    with codecs.open(fn, 'r', encoding='utf-8', errors='ignore') as fo:
        not_eof = True
        while not_eof:
            line = fo.readline()
            if line:
                line = line.strip()
                line = line.replace('\t', ' ')
                if ( line.startswith('/*--') and 
                        line.endswith('*/') and 
                        not line.startswith('/*---') ):
                    raw_meta.append(line)
            else:
                not_eof = False
        fo.close()
    return raw_meta

def recurse_dir( start_path ):
    result=[]
    for (path,dirs,files) in os.walk(start_path):
        for file in files:
            if ( file.endswith('.c') or
                 file.endswith('.h') or
                 file.endswith('.cpp') ):
                result.append(path+'/'+file)
    return result

parser = argparse.ArgumentParser(description='Scan dirs for meta and generate cache output.')
parser.add_argument('--dir', nargs='*', help='directories to scan')

file_count=0
json_text=''
args = parser.parse_args()
if ( args.dir != None ):
    json_text+='{"cache":[\n'
    for dir in range(len(args.dir)): 
        dir_name=args.dir[dir]
        source_files = recurse_dir(dir_name)
        for fileno in range(len(source_files)):
            fn=source_files[fileno]
            if ( file_count ):
                json_snippet=' ,\n '
            else:
                json_snippet=' '
            json_snippet+='{\n  "fn":"'+fn+'"'
            raw_meta = extract_raw_meta(source_files[fileno])
            if ( len(raw_meta) > 0 ):
                json_snippet+=',\n  "meta":['
                for metano in range(len(raw_meta)):
                    raw_meta_str = raw_meta[metano]
                    json_snippet+='  "'+extract_cooked_meta( raw_meta_str )+'"'
                    if ( metano < len(raw_meta)-1 ):
                        json_snippet+=','
                json_snippet+=']\n'
            json_snippet+=' }'
            json_text+=(json_snippet+'\n')
            file_count+=1
    json_text+=']}\n'
    print(json.dumps(json.loads(json_text), sort_keys=False, indent=4))

